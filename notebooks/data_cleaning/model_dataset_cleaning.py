# -*- coding: utf-8 -*-
"""model_dataset_cleaning

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qj3Fi39DY0e4jKoCDYt7Qe36aMLTgcli

This dataset represents a fully enriched, time-indexed, SKU-level view of e-commerce operations.
Each row captures weekly metrics for a single SKU, integrating sales, product metadata, inventory status, user engagement, pricing environment, and returns behavior.
"""

# import libaries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path

"""### I prefer modular coding for better performance, scalabity and reusability"""

''' You have 104 rows (out of 34,598) with missing product-related metadata:

brand, category	-> 104 ->	Categorical	-> For SKU classification
MRP, base_cost, margin, weeks_since_launch	-> 104 ->	Numeric -> Derived from product master
launch_date ->	104	-> Object (datetime later)	-> Needed for "age of product" analysis'''

def load_weekly_dataset(path: str | Path) -> pd.DataFrame:
    return pd.read_csv(path)

def report_nulls(df: pd.DataFrame) -> None:
    nulls = df.isnull().sum()
    nulls = nulls[nulls > 0].sort_values(ascending=False)
    print("Null value summary:\n")
    print(nulls.to_string())

def drop_incomplete_product_metadata(df: pd.DataFrame) -> pd.DataFrame:
    critical_cols = [
        'brand', 'category', 'MRP', 'base_cost',
        'launch_date', 'margin', 'weeks_since_launch'
    ]
    before = len(df)
    df_cleaned = df.dropna(subset=critical_cols).reset_index(drop=True)
    after = len(df_cleaned)
    dropped = before - after
    print(f"Dropped {dropped} rows with missing critical product metadata.")
    return df_cleaned

def save_dataset(df: pd.DataFrame, out_path: str | Path) -> None:
    df.to_csv(out_path, index=False)
    print(f"Saved cleaned dataset to: {out_path}")

def clean_dataset_for_lstm(
    in_path: str,
    out_path: str,
    strategy: str = "drop"
) -> pd.DataFrame:

    print("Loading raw dataset...")
    df = load_weekly_dataset(in_path)

    print("Reporting missing values before cleaning:")
    report_nulls(df)

    if strategy == "drop":
        print("Applying strategy: drop")
        df = drop_incomplete_product_metadata(df)
    else:
        raise ValueError("Unsupported strategy for LSTM: Only 'drop' is valid here.")

    print("Reporting missing values after cleaning:")
    report_nulls(df)

    save_dataset(df, out_path)
    return df

# Replace with your real path
raw_path = "final_weekly_dataset_raw_v1.csv"
clean_path = "final_weekly_dataset_lstm_v1.csv"

df_lstm_ready = clean_dataset_for_lstm(
    in_path=raw_path,
    out_path=clean_path,
    strategy="drop"
)



















